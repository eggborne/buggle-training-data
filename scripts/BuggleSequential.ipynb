{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D, Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "import gzip\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_puzzle_data(file_path):\n",
    "    !cd buggle-training-data && git pull\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "      puzzle_data = json.load(f)\n",
    "      return puzzle_data\n",
    "\n",
    "alphabet = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\n",
    "def one_hot_encode(matrix):\n",
    "    one_hot_encoded = np.zeros((len(matrix), len(matrix[0]), len(alphabet)))\n",
    "    for i, row in enumerate(matrix):\n",
    "        for j, char in enumerate(row):\n",
    "            one_hot_encoded[i, j, char_to_int[char]] = 1\n",
    "    return one_hot_encoded\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lr = 0.001  \n",
    "    drop = 0.5          \n",
    "    epochs_drop = 20.0  \n",
    "    lr = initial_lr * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "def extract_features(puzzles):\n",
    "    num_puzzles = len(puzzles)\n",
    "    matrix_features = np.zeros((num_puzzles, *(4,4), 26))\n",
    "    outcomes = np.zeros(num_puzzles)\n",
    "\n",
    "    for idx, puzzle in enumerate(puzzles):\n",
    "        matrix = puzzle['matrix']\n",
    "        total_words = puzzle['totalWords']\n",
    "        matrix_features[idx] = one_hot_encode(matrix)\n",
    "        outcomes[idx] = total_words\n",
    "\n",
    "    return np.array(matrix_features), np.array(outcomes)\n",
    "\n",
    "def preprocess_data(matrix_features, outcomes):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(matrix_features, outcomes, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def augment_data(matrix_features, outcomes):\n",
    "    augmented_matrices = []\n",
    "    augmented_outcomes = []\n",
    "\n",
    "    for idx, matrix in enumerate(matrix_features):\n",
    "        # Perform rotations\n",
    "        matrix_90 = np.rot90(matrix)\n",
    "        # matrix_180 = np.rot90(matrix, k=2)\n",
    "        matrix_270 = np.rot90(matrix, k=3)\n",
    "\n",
    "        # Perform flips\n",
    "        # matrix_flipX = np.fliplr(matrix)\n",
    "        # matrix_flipY = np.flipud(matrix)\n",
    "\n",
    "        # Perform diagonal flips with explicit axes\n",
    "        # matrix_diagonal_tl_br = np.transpose(matrix, axes=(1, 0, 2))  # Top-left to bottom-right diagonal flip\n",
    "        # matrix_diagonal_tr_bl = np.transpose(np.fliplr(matrix), axes=(1, 0, 2))  # Top-right to bottom-left diagonal flip\n",
    "\n",
    "        # Collect all unique transformations\n",
    "        transformations = [\n",
    "            matrix,\n",
    "            matrix_90,\n",
    "            # matrix_180,\n",
    "            matrix_270,\n",
    "            # matrix_flipX,\n",
    "            # matrix_flipY,\n",
    "            # matrix_diagonal_tl_br,\n",
    "            # matrix_diagonal_tr_bl,\n",
    "        ]\n",
    "\n",
    "        # Remove duplicate transformations\n",
    "        unique_transformations = []\n",
    "        for transform in transformations:\n",
    "            if not any(np.array_equal(transform, unique) for unique in unique_transformations):\n",
    "                unique_transformations.append(transform)\n",
    "\n",
    "        # Add the unique transformations to the augmented list\n",
    "        augmented_matrices.extend([np.array(transform) for transform in unique_transformations])\n",
    "        augmented_outcomes.extend([outcomes[idx]] * len(unique_transformations))\n",
    "\n",
    "    return np.array(augmented_matrices), np.array(augmented_outcomes)\n",
    "\n",
    "def build_model2(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (2, 2), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Input(shape=(4, 4, 26)),\n",
    "        Conv2D(hp.Int('conv_units', min_value=32, max_value=128, step=32), (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(hp.Int('conv_units', min_value=32, max_value=128, step=32), (2, 2), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(hp.Int('dense_units', min_value=64, max_value=256, step=64), activation='relu'),\n",
    "        Dropout(hp.Float('dropout_rate', min_value=0.3, max_value=0.5, step=0.1)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    puzzle_data = load_puzzle_data('buggle-training-data/training_data-100000.gz')\n",
    "    print(f\"Got {len(puzzle_data)} puzzles.\")\n",
    "    matrix_features, outcomes = extract_features(puzzle_data)\n",
    "    print(f\"Loaded {len(matrix_features)} matrix features.\")\n",
    "    print(f\"Loaded {len(outcomes)} outcomes.\")\n",
    "\n",
    "    augmented_matrix_features, augmented_outcomes = augment_data(matrix_features, outcomes)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = preprocess_data(augmented_matrix_features, augmented_outcomes)\n",
    "    print(f\"Preprocessed {len(X_train)} training examples, {len(X_val)} validation examples, and {len(X_test)} test examples.\")\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "\n",
    "    # tuner = kt.Hyperband(build_model,\n",
    "    #                     objective='val_mean_absolute_error',\n",
    "    #                     max_epochs=50,\n",
    "    #                     factor=3,\n",
    "    #                     directory='my_dir',\n",
    "    #                     project_name='hyperparam_tuning')\n",
    "\n",
    "    # stop_early = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    # tuner.search(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[stop_early])\n",
    "\n",
    "    # best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    # print(f\"Best Hyperparameters: {best_hps}\")\n",
    "\n",
    "    # model = tuner.hypermodel.build(best_hps)\n",
    "    # history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[stop_early])\n",
    "\n",
    "    # test_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "    # print(f\"Test Loss: {test_results[0]}, Test MAE: {test_results[1]}\")\n",
    "\n",
    "\n",
    "    model = build_model(X_train.shape[1:])\n",
    "    print(\"Model built.\")\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001, verbose=1)\n",
    "\n",
    "    history = model.fit(\n",
    "      X_train, y_train,\n",
    "      epochs=50,\n",
    "      batch_size=32,\n",
    "      validation_data=(X_val, y_val),\n",
    "      verbose=1,\n",
    "      callbacks=[early_stopping, reduce_lr, lr_scheduler]\n",
    "    )\n",
    "\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Test Loss: {test_results[0]}, Test MAE: {test_results[1]}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history['mean_absolute_error'], label='MAE (training data)')\n",
    "    plt.plot(history.history['val_mean_absolute_error'], label='MAE (validation data)')\n",
    "    plt.title('MAE for Puzzle Prediction')\n",
    "    plt.ylabel('MAE value')\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "    model.save('buggle-training-data/models/prediction_model-8.keras')\n",
    "    print('Model saved.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
