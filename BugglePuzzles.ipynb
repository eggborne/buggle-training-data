{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load and update puzzle data\n",
    "def load_puzzle_data(file_path):\n",
    "    !cd buggle-training-data && git pull\n",
    "    with open('buggle-training-data/training_data.json', 'r') as f:\n",
    "      puzzle_data = json.load(f)\n",
    "      return puzzle_data\n",
    "\n",
    "def extract_features(puzzle_data):\n",
    "    all_features = []\n",
    "    for puzzle in puzzle_data:\n",
    "        try:\n",
    "            matrix = puzzle['features']['matrix']\n",
    "            if any(len(row) != 5 for row in matrix) or len(matrix) != 5:  # Ensure each matrix is 5x5\n",
    "                print(\"Error: Matrix is not 5x5\")\n",
    "                continue  # Skip this puzzle\n",
    "\n",
    "            ascii_matrix = np.array([[ord(char) for char in row] for row in matrix])\n",
    "            all_features.append(ascii_matrix)\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing key in puzzle: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing puzzle: {e}\")\n",
    "            continue\n",
    "\n",
    "    return np.array(all_features)\n",
    "\n",
    "def preprocess_data(all_features, outcomes):\n",
    "    # Existing preprocessing steps...\n",
    "    all_features = np.expand_dims(all_features, axis=-1)\n",
    "    original_shape = all_features.shape\n",
    "    all_features = all_features.reshape(-1, original_shape[1] * original_shape[2])\n",
    "    scaler = MinMaxScaler()\n",
    "    all_features = scaler.fit_transform(all_features)\n",
    "    all_features = all_features.reshape(original_shape[0], original_shape[1], original_shape[2], 1)\n",
    "\n",
    "    # Updated splitting logic to include a validation set\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(all_features, outcomes, test_size=0.3, random_state=42)  # 70% train, 30% temp\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # Split temp into 50% val, 50% test\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "      Input(shape=(5, 5, 1)),  # Define the input shape explicitly here\n",
    "      Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "      MaxPooling2D((2, 2)),\n",
    "      Dropout(0.25),\n",
    "      Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "      MaxPooling2D((2, 2)),\n",
    "      Dropout(0.25),\n",
    "      Flatten(),\n",
    "      Dense(128, activation='relu'),\n",
    "      Dropout(0.5),\n",
    "      Dense(1)  # Assuming a regression task for predicting 'totalWords'\n",
    "  ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# Main function to run the script\n",
    "def main():\n",
    "    # Load data\n",
    "    puzzle_data = load_puzzle_data('buggle-training-data/training_data.json')\n",
    "    print(f\"Got {len(puzzle_data)} puzzles.\")\n",
    "    all_features = extract_features(puzzle_data)\n",
    "    print(f\"Loaded {len(all_features)} features.\")\n",
    "    outcomes = np.array([puzzle['outcomes']['totalWords'] for puzzle in puzzle_data])\n",
    "    print(f\"Loaded {len(outcomes)} outcomes.\")\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = preprocess_data(all_features, outcomes)\n",
    "    print(f\"Preprocessed {len(X_train)} training examples and {len(X_test)} test examples and {len(X_val)} validation examples.\")\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    # Set up early stopping\n",
    "    early_stopping_monitor = EarlyStopping(\n",
    "        monitor='val_mean_absolute_error',\n",
    "        patience=10,  # Number of epochs with no improvement after which training will be stopped\n",
    "        restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity\n",
    "    )\n",
    "    \n",
    "    # Train the model with the early stopping callback\n",
    "    history = model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=100, \n",
    "        batch_size=32, \n",
    "        validation_split=0.2, \n",
    "        verbose=1, \n",
    "        callbacks=[early_stopping_monitor]\n",
    "    )\n",
    "    \n",
    "    print(\"Finished training.\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Test Loss: {test_results[0]}, Test MAE: {test_results[1]}\")\n",
    "\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history['mean_absolute_error'], label='MAE (training data)')\n",
    "    plt.plot(history.history['val_mean_absolute_error'], label='MAE (validation data)')\n",
    "    plt.title('MAE for Puzzle Prediction')\n",
    "    plt.ylabel('MAE value')\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "    # def wrapped_predict(X):\n",
    "    #     return model.predict(X).flatten()\n",
    "\n",
    "    # results = permutation_importance(wrapped_predict, X_val, y_val, scoring='neg_mean_absolute_error', n_repeats=10, random_state=42)\n",
    "\n",
    "    # # Get importance and print\n",
    "    # importance = results.importances_mean\n",
    "    # feature_names = ['Feature1', 'Feature2', 'Feature3', ...]  # Update these based on your actual features\n",
    "    # for i, imp in enumerate(importance):\n",
    "    #     print(f\"{feature_names[i]} Importance: {imp}\")\n",
    "\n",
    "# Run the script\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
