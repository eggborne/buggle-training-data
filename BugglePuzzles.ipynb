{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import gzip\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_puzzle_data(file_path):\n",
    "    !cd buggle-training-data && git pull\n",
    "    with gzip.open(file_path, 'rt') as f:  # Open the gzip file\n",
    "      puzzle_data = json.load(f)\n",
    "      return puzzle_data\n",
    "\n",
    "def one_hot_encode(matrix):\n",
    "    # Create a mapping of letters to integer indices\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "\n",
    "    one_hot_encoded = np.zeros((len(matrix), len(matrix[0]), len(alphabet)))\n",
    "    for i, row in enumerate(matrix):\n",
    "        for j, char in enumerate(row):\n",
    "            one_hot_encoded[i, j, char_to_int[char]] = 1\n",
    "    return one_hot_encoded\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lr = 0.01  # Start with a higher learning rate\n",
    "    drop = 0.5  # Reduce learning rate by half\n",
    "    epochs_drop = 10.0  # Reduce every 10 epochs\n",
    "    lr = initial_lr * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "def extract_features(puzzles):\n",
    "    matrix_features = []\n",
    "    outcomes = []\n",
    "\n",
    "    for puzzle in puzzles:\n",
    "        matrix = one_hot_encode(puzzle['mtx'])\n",
    "        total_words = puzzle['tw']\n",
    "        matrix_features.append(matrix)\n",
    "        outcomes.append(total_words)\n",
    "\n",
    "    return np.array(matrix_features), np.array(outcomes)\n",
    "\n",
    "def preprocess_data(matrix_features, outcomes):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(matrix_features, outcomes, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),  # Adjust input shape based on one-hot encoding\n",
    "        Conv2D(16, (2, 2), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1)  # Output layer for regression\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def augment_data(matrix_features, outcomes):\n",
    "    augmented_matrices = []\n",
    "    augmented_outcomes = []\n",
    "\n",
    "    for idx, matrix in enumerate(matrix_features):\n",
    "        # Rotate matrix\n",
    "        matrix_90 = np.rot90(matrix)\n",
    "\n",
    "        augmented_matrices.extend([matrix, matrix_90, matrix_90])\n",
    "        augmented_outcomes.extend([outcomes[idx]] * 3)  # replicate each outcome 6 times\n",
    "\n",
    "    return np.array(augmented_matrices), np.array(augmented_outcomes)\n",
    "\n",
    "\n",
    "# Main function to run the script\n",
    "def main():\n",
    "    # Load data\n",
    "    puzzle_data = load_puzzle_data('buggle-training-data/training_data.json')\n",
    "    print(f\"Got {len(puzzle_data)} puzzles.\")\n",
    "    matrix_features, outcomes = extract_features(puzzle_data)\n",
    "    print(f\"Loaded {len(matrix_features)} matrix features.\")\n",
    "    print(f\"Loaded {len(outcomes)} outcomes.\")\n",
    "\n",
    "    augmented_matrix_features, augmented_outcomes = augment_data(matrix_features, outcomes)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = preprocess_data(augmented_matrix_features, augmented_outcomes)\n",
    "    print(f\"Preprocessed {len(X_train)} training examples and {len(X_test)} test examples.\")\n",
    "    model = build_model(X_train.shape[1:])\n",
    "    print(\"Model built.\")\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001, verbose=1)\n",
    "\n",
    "    history = model.fit(\n",
    "      X_train, y_train,\n",
    "      epochs=50,\n",
    "      batch_size=32,\n",
    "      validation_data=(X_val, y_val),\n",
    "      verbose=1,\n",
    "      callbacks=[reduce_lr, early_stopping]\n",
    "  )\n",
    "\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Test Loss: {test_results[0]}, Test MAE: {test_results[1]}\")\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history['mean_absolute_error'], label='MAE (training data)')\n",
    "    plt.plot(history.history['val_mean_absolute_error'], label='MAE (validation data)')\n",
    "    plt.title('MAE for Puzzle Prediction')\n",
    "    plt.ylabel('MAE value')\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "# Run the script\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
